{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping for the 2022 NFL Weather for each week "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nfl_weather(html):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    games_data = []\n",
    "\n",
    "    game_boxes = soup.find_all('div', class_='game-box')\n",
    "    for game in game_boxes:\n",
    "        # Extracting Date and Time\n",
    "        date_time_div = game.find('div', class_='fw-bold text-wrap')\n",
    "        date_time = date_time_div.get_text(strip=True) if date_time_div else None\n",
    "\n",
    "        # Extracting team names and scores\n",
    "        team_boxes = game.find_all('div', class_='team-game-box')\n",
    "        if team_boxes and len(team_boxes) >= 2:\n",
    "            away_team_span = team_boxes[0].find('span', class_='fw-bold')\n",
    "            away_team = away_team_span.get_text(strip=True) if away_team_span else None\n",
    "            away_score_div = team_boxes[0].find('div', class_='game-points')\n",
    "            away_score = away_score_div.get_text(strip=True) if away_score_div else None\n",
    "\n",
    "            home_team_span = team_boxes[1].find('span', class_='fw-bold ms-1')\n",
    "            home_team = home_team_span.get_text(strip=True) if home_team_span else None\n",
    "            home_score_div = team_boxes[1].find('div', class_='game-points')\n",
    "            home_score = home_score_div.get_text(strip=True) if home_score_div else None\n",
    "        else:\n",
    "            away_team, home_team, away_score, home_score = None, None, None, None\n",
    "\n",
    "        # Extracting Weather Conditions\n",
    "        weather_info = game.select('.text-break.col-md-4.d-flex')[0]\n",
    "        temperature = weather_info.find_all('span')[0].get_text(strip=True) if weather_info else None\n",
    "        weather_condition = weather_info.find_all('span')[1].get_text(strip=True) if weather_info else None\n",
    "\n",
    "        # Appending the extracted data\n",
    "        games_data.append({\n",
    "            'Date_Time': date_time,\n",
    "            'Away_Team': away_team,\n",
    "            'Home_Team': home_team,\n",
    "            'Away_Score': away_score,\n",
    "            'Home_Score': home_score,\n",
    "            'Temperature': temperature,\n",
    "            'Weather_Condition': weather_condition\n",
    "        })\n",
    "\n",
    "        # Optional: Logging each game's data\n",
    "        # logging.info(f\"Scraped data: {date_time}, {away_team} vs {home_team}, Score: {away_score}-{home_score}, Temp: {temperature}, Condition: {weather_condition}\")\n",
    "\n",
    "    return games_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_nfl_weather_for_season():\n",
    "    all_weeks_data = []\n",
    "    for week in range(1, 22):  # Including weeks for playoffs and Super Bowl\n",
    "        url = f\"https://www.nflweather.com/week/2022/week-{week}\"\n",
    "        response = requests.get(url)\n",
    "        week_data = parse_nfl_weather(response.content)\n",
    "        all_weeks_data.extend(week_data)\n",
    "        print(f\"Week {week} data scraped\")\n",
    "    \n",
    "    return all_weeks_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 1 data scraped\n",
      "Week 2 data scraped\n",
      "Week 3 data scraped\n",
      "Week 4 data scraped\n",
      "Week 5 data scraped\n",
      "Week 6 data scraped\n",
      "Week 7 data scraped\n",
      "Week 8 data scraped\n",
      "Week 9 data scraped\n",
      "Week 10 data scraped\n",
      "Week 11 data scraped\n",
      "Week 12 data scraped\n",
      "Week 13 data scraped\n",
      "Week 14 data scraped\n",
      "Week 15 data scraped\n",
      "Week 16 data scraped\n",
      "Week 17 data scraped\n",
      "Week 18 data scraped\n",
      "Week 19 data scraped\n",
      "Week 20 data scraped\n",
      "Week 21 data scraped\n"
     ]
    }
   ],
   "source": [
    "season_data = scrape_nfl_weather_for_season()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./src/nfl_weather_data.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(season_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file_path = './src/nfl_weather_data.csv' \n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Data saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the schedule and weather data\n",
    "url\n",
    "schedule_df = pd.read_csv('')\n",
    "weather_df = pd.read_csv('path_to_weather_data.csv')\n",
    "\n",
    "# Preprocess the date in weather data to match the schedule data\n",
    "weather_df['Game_Date'] = pd.to_datetime(weather_df['Date_Time']).dt.strftime('%Y%m%d')\n",
    "\n",
    "# Create a unique identifier in both dataframes for merging\n",
    "schedule_df['Game_Identifier'] = schedule_df['Game_Date'].astype(str) + schedule_df['Home_Team'] + schedule_df['Away_Team']\n",
    "weather_df['Game_Identifier'] = weather_df['Game_Date'].astype(str) + weather_df['Home_Team'] + weather_df['Away_Team']\n",
    "\n",
    "# Merge the dataframes on the identifier\n",
    "merged_df = pd.merge(schedule_df, weather_df, on='Game_Identifier', how='left')\n",
    "\n",
    "# Now you have a merged dataframe with both schedule and weather information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
